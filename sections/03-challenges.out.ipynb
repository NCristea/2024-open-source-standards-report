{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "# Opportunities and risks for open-source standards\n",
    "\n",
    "At the same time, these tools and practices are associated with risks that need to be mitigated.\n",
    "\n",
    "## Flexibility vs. Stability\n",
    "\n",
    "One of the defining characteristics of OSS is its dynamism and its rapid evolution. Because OSS can be used by anyone and, in most cases, contributions can be made by anyone, innovations flow into OSS in a bottom-up fashion from user/developers. Pathways to contribution by members of the community are often well-defined: both from the technical perspective (e.g., through a pull request on GitHub, or other similar mechanisms), as well as from the social perspective (e.g., whether contributors need to accept certain licensing conditions through a contributor licensing agreement) and the socio-technical perspective (e.g., how many people need to review a contribution, what are the timelines for a contribution to be reviewed and accepted, what are the release cycles of the software that make the contribution available to a broader community of users, etc.). Similarly, open-source standards may also find themselves addressing use cases and solutions that were not originally envisioned through bottom-up contributions of members of a research community to which the standard pertains. However, while this dynamism provides an avenue for flexibility it also presents a source of tension. This is because data and metadata standards apply to already existing datasets, and changes may affect the compliance of these existing datasets. Similarly, analysis technology stacks that are developed based on an existing version of a standard have to adapt to the introduction of new ideas and changes into a standard. Dynamic changes of this sort therefore risk causing a loss of faith in the standard by a user community, and migration away from the standard. Similarly, if a standard evolves too rapidly, users may choose to stick to an outdated version of a standard for a long time, creating strains on the community of developers and maintainers of a standard who will need to accommodate long deprecation cycles.\n",
    "\n",
    "## Mismatches between standards developers and user communities\n",
    "\n",
    "There is an inherent gap in both interest and ability to engage with the technical details undergirding standards and their development between the core developers of the standard and their users. In extreme cases, these interests may even be at odds, as developers implement sophisticated mechanisms to automate the creation and validation of the standard or advocate for more technically advanced mechanisms for evolving the standard. These advanced capabilities offer more robust development practices and consistency in cases where the standards are complex and elaborate. On the other hand, they may end up leaving potential users sidelined in the development of the standard, and limiting their ability to provide feedback about the practical implications of changes to the standards.\n",
    "\n",
    "## Unclear pathways for standards success\n",
    "\n",
    "Standards typically develop organically through sustained and persistent efforts from dedicated groups of data practitioners. These include scientists and the broader ecosystem of data curators and users. However, there is no playbook on the structure and components of a data standard, or the pathway that moves a data implementation to a data standard. As a result, data standardization lacks formal avenues for success and recognition, for example through dedicated research grants (and see ([**sec-cross-sector?**](#ref-sec-cross-sector)))\n",
    "\n",
    "## Cross-domain funding gaps\n",
    "\n",
    "Data standardization investment is justified if the standard is generalizable beyond any specific science domain. However while the use cases are domain sciences based, data standardization is seen as a data infrastructure and not a science investment. Moreover, due to how science research funding works, scientists lack incentives to work across domains or to work on infrastructure problems.\n",
    "\n",
    "## Data instrumentation issues\n",
    "\n",
    "Data for scientific observations are often generated by proprietary instrumentation due to commercialization or other profit-driven incentives. There is a lack of regulatory oversight to adhere to available standards or evolve Significant data transformation is required to get data to a state that is amenable to standards, if available. If not available, there is a lack of incentive to set aside investment or resources to invest in establishing data standards.\n",
    "\n",
    "### Harnessing new computing paradigms and technologies\n",
    "\n",
    "Open-source standards development faces the challenges of adapting to new computing paradigms and technologies. Cloud computing provides a particularly stark set of opportunities and challenges. On the one hand, cloud computing offers practical solutions for many challenges of contemporary data-driven research. For example, the scalability of cloud resources addresses some of the challenges of the scale of data that is produced by instruments in many fields. The cloud also makes data access relatively straightforward, because of the ability to determine data access permissions in a granular fashion. On the other hand, cloud computing requires reinstrumenting many data formats. This is because cloud data access patterns are fundamentally different from the ones that are used in local posix-style file-systems. Suspicion of cloud computing comes in two different flavors: the first by researchers and administrators who may be wary of costs associated with cloud computing, and especially with the difficulty of predicting these costs. Projects such as NSF’s Cloud Bank seek to mitigate some of these concerns, by providing an additional layer of transparency into cloud costs ([Norman et al. 2021](#ref-Norman2021CloudBank)). The other type of objection relates to the fact that cloud computing services, by their very nature, are closed ecosystems that resist portability and interoperability. Some aspects of the services are always going to remain hidden and privy only to the cloud computing service provider. In this respect, cloud computing runs afoul of some of the appealing aspects of OSS. That said, the development of “cloud native” standards can provide significant benefits in terms of the research that can be conducted. For example, NOAA plans to use cloud computing for integration across the multiple disparate datasets that it collects to build knowledge graphs that can be queried by researchers to answer questions that can only be answered through this integration. Putting all the data “in one place” should help with that. Adaptation to the cloud in terms of data standards has driven development of new file formats. A salient example is the ZARR format ([Miles et al. 2024](#ref-zarr)), which supports random access into array-based datasets stored in cloud object storage, facilitating scalable and parallelized computing on these data. Indeed, data standards such as NWB (neuroscience) and OME (microscopy) now use ZARR as a backend for cloud-based storage. In other cases, file formats that were once not straightforward to use in the cloud, such as HDF5 and TIFF have been adapted to cloud use (e.g., through the cloud-optimized geoTIFF format).\n",
    "\n",
    "## Sustainability\n",
    "\n",
    "## The importance of automated validation\n",
    "\n",
    "Miles, Alistair, jakirkham, M Bussonnier, Josh Moore, Dimitri Papadopoulos Orfanos, Davis Bennett, David Stansby, et al. 2024. “Zarr-Developers/Zarr-Python: V3.0.0-Alpha.” Zenodo. <https://doi.org/10.5281/zenodo.11592827>.\n",
    "\n",
    "Norman, Michael, Vince Kellen, Shava Smallen, Brian DeMeulle, Shawn Strande, Ed Lazowska, Naomi Alterman, et al. 2021. “<span class=\"nocase\">CloudBank: Managed Services to Simplify Cloud Access for Computer Science Research and Education</span>.” In *Practice and Experience in Advanced Research Computing*. PEARC ’21. New York, NY, USA: Association for Computing Machinery. <https://doi.org/10.1145/3437359.3465586>."
   ],
   "id": "0c73f066-f4bd-4479-bb4e-4f64274b886b"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
