% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Towards an open-source model for data and metadata standards},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Towards an open-source model for data and metadata standards}
\author{Ariel Rokem}
\date{}

\begin{document}
\maketitle

\section{ðŸš§ Under construction ðŸš§}\label{under-construction}

Please excuse our dust while we work on this report, which is currently
under heavy construction.

\section{Abstract}\label{abstract}

Recent progress in machine learning and artificial intelligence promises
to advance research and understanding across a wide range of fields and
activities. In tandem, an increased awareness of the importance of open
data for reproducibility and scientific transparency is making inroads
in fields that have not traditionally produced large publicly available
datasets. Data sharing requirements from publishers and funders, as well
as from other stakeholders, have also created pressure to make datasets
with research and/or public interest value available through digital
repositories. However, to make the best use of existing data, and
facilitate the creation of useful future datasets, robust, interoperable
and usable standards need to evolve and adapt over time. The open-source
development model provides significant potential benefits to the process
of standard creation and adaptation. In particular, development and
adaptation of standards can use long-standing socio-technical processes
that have been key to managing the development of software, and allow
incorporating broad community input into the formulation of these
standards. By adhering to open-source standards to formal descriptions
(e.g., by implementing schemata for standard specification, and/or by
implementing automated standard validation), processes such as automated
testing and continuous integration, which have been important in the
development of open-source software, can be adopted in defining data and
metadata standards as well. Similarly, open-source governance provides a
range of stakeholders a voice in the development of standards,
potentially enabling use-cases and concerns that would not be taken into
account in a top-down model of standards development. On the other hand,
open-source models carry unique risks that need to be incorporated into
the process.

\section{Introduction}\label{introduction}

Data-intensive discovery has become an important mode of knowledge
production across many research fields and has had a significant and
broad impact across all of society. This is becoming increasingly
salient as recent developments in machine learning and artificial
intelligence (AI) promise to increase the value of large,
multi-dimensional, heterogeneous data sources. Coupled with these new
machine learning techniques, these datasets can help us understand
everything from the cellular operations of the human body, through
business transactions on the internet, to the structure and history of
the universe. However, the development of new machine learning methods,
and data-intensive discovery more generally, rely heavily on the
availability and usability of these large datasets. Data can be openly
available but still not useful if it cannot be properly understood. In
current conditions in which almost all of the relevant data is stored in
digital formats, and many relevant datasets can be found through the
communication networks of the world wide web, Findability,
Accessibility, Interoperability and Reusability (FAIR) principles for
data management and stewardship become critically important
\cite{Wilkinson2016FAIR}.

One of the main mechanisms through which these principles are promoted
is the development of \emph{standards} for data and metadata. Standards
can vary in the level of detail and scope, and encompass such things as
\emph{file formats} for the storing of certain data types,
\emph{schemas} for databases that store a range of data types,
\emph{ontologies} to describe and organize metadata in a manner that
connects it to field-specific meaning, as well as mechanisms to describe
\emph{provenance} of different data derivatives. The importance of
standards was underscored in a recent report report by the Subcommittee
on Open Science of the National Science and Technology Council on
``Desirable characteristics of data repositories for federally funded
research'' \cite{nstc2022desirable}. The report explicitly called out
the importance of ``allow{[}ing{]} datasets and metadata to be accessed,
downloaded, or exported from the repository in widely used, preferably
non-proprietary, formats consistent with standards used in the
disciplines the repository serves.'' This highlights the need for data
and metadata standards across a variety of different kinds of data. In
addition, a report from the National Institute of Standards and
Technology on ``U.S. Leadership in AI: A Plan for Federal Engagement in
Developing Technical Standards and Related Tools'' emphasized that --
specifically for the case of AI -- ``U.S. government agencies should
prioritize AI standards efforts that are {[}\ldots{]} Consensus-based,
{[}\ldots{]} Inclusive and accessible, {[}\ldots{]} Multi-path,
{[}\ldots{]} Open and transparent, {[}\ldots{]} and {[}that{]} Result in
globally relevant and non-discriminatory standards\ldots{}''
\cite{NIST2019}. The converging characteristics of standards that arise
from these reports suggest that considerable thought needs to be given
to the manner in which standards arise, so that these goals are
achieved.

Standards for a specific domain can come about in various ways, but very
broadly speaking two kinds of mechanisms can generate a standard for a
specific type of data: (i) top-down: in this case a (usually) small
group of people develop the standard and disseminate it to the
communities of interest with very little input from these communities.
An example of this mode of standards development can occur when an
instrument is developed by a manufacturer and users of this instrument
receive the data in a particular format that was developed in tandem
with the instrument; and (ii) bottom-up: in this case, standards are
developed by a larger group of people that convene and reach consensus
about the details of the standard in an attempt to cover a large range
of use-cases. Most standards are developed through an interplay between
these two modes, and understanding how to make the best of these modes
is critical in advancing the development of data and metadata standards.

One source of inspiration for bottom-up development of robust, adaptable
and useful standards comes from open-source software (OSS). OSS has a
long history going back to the development of the Unix operating system
in the late 1960s. Over the time since its inception, the large
community of developers and users of OSS have have developed a host of
socio-technical mechanisms that support the development and use of OSS.
For example, the Open Source Initiative (OSI), a non-profit organization
that was founded in 1990s has evolved a set of guidelines for licensing
of OSS that is designed to protect the rights of developers and users.
Technical tools to support the evolution of open-source software include
software for distributed version control, such as the Git Source-code
management system. When these social and technical innovations are put
together they enable a host of positive defining features of OSS, such
as transparency, collaboration, and decentralization. These features
allow OSS to have a remarkable level of dynamism and productivity, while
also retaining the ability of a variety of stakeholders to guide the
evolution of the software to take their needs and interests into
account.

A necessary complement to these technical tools and legal instruments
have been a host of practices that define the social interactions
\emph{within} communities of OSS developers and users, and structures
for governing these communities. While many OSS communities started as
projects led by individual founders (so-called benevolent dictators for
life, or BDFL; a title first bestowed on the originator of the Python
programming language, Guido Van Rossum \cite{Van_Rossum2008BDFL}),
recent years have led to an increased understanding that minimal
standards of democratic governance are required in order for OSS
communities to develop and flourish. This has led to the adoption of
codes of conduct that govern the standards of behavior and communication
among project stakeholders. It has also led to the establishment of
democratically elected steering councils/committees from among the
members and stakeholders of an OSS project's community.

It was also within the Python community that an orderly process for
community-guided evolution of an open-source software project emerged,
through the Python Enhancement Proposal (PEP) mechanism
\cite{Warsaw2000PEP1}, which lays out how major changes to the software
should be proposed, advocated for, and eventually decided on. While
these tools, ideas, and practices evolved in developing software, they
are readily translated to other domains. For example, OSS notions
surrounding IP have given rise to the Creative Commons movement that has
expanded these notions to apply to a much wider range of human creative
endeavours. Similarly OSS notions regarding collaborative structures
have pervaded the current era of open science and team science
\cite{Baumgartner2023TeamScience, Koch2016TeamScience}.

\section{Challenges for open source data and metadata standards, and
some
solutions}\label{challenges-for-open-source-data-and-metadata-standards-and-some-solutions}

\subsection{Too much flexibility, or too
little}\label{too-much-flexibility-or-too-little}

It's a story as old as time (or at least as old as standards): users
fail to consider existing standards, or perceive an existing standard as
not offering enough flexibility to cover some use case, and they embark
on the development of a new standard \footnote{So old in fact that an
  oft-cited \href{https://xkcd.com/927/}{XKCD comic} has been devoted to
  it.}.

Another failure is the mismatch between developers of the standard and
users. There is an iherent gap in both interest and ability to engage
with the technical details undergirding standards and their development
between the developers of the standard and their users. In extreme
cases, these interests may be at odds, as developers implement
sophisticated mechanisms to automate the creation of the standard or
advocate for more technically advanced mechanisms for evolving the
standard, leaving potential users sidelined in the development of the
standard, and limiting their ability to provide feedback about the
practical implications of changes to the standards.

\subsection{Sustainability}\label{sustainability}

\subsection{The importance of automated
validation}\label{the-importance-of-automated-validation}

\section{Recommendations}\label{recommendations}

We make the following recommendations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Training for data stewards and career paths that encourage this role.
\item
  Development of meta-standards or standards-of-standards. These are
  descriptions of cross-cutting best-practices. These can be used as a
  basis of the analysis or assessment of an existing standard, or as
  guidelines to develop new standards.
\end{enumerate}



\end{document}
